[{"content":"Case  生成一组人物IP Stable Diffusion模型ReV Animated + ControlNet模型 control_v11p_sd15_openpose    text2img - prompt\nPrompt (masterpiece, best quality, ultra-detailed), (full body:1.2, beautiful detailed face, beautiful detailed eyes, white background,simple background), 1 girl,Splatoon,cute,smile,gray blue hair,Orange sweater,light blue short skirt Negative Prompt (low quality:1.3),(worst quality:1.3)   ControlNet骨架图片\n   效果图片\n   Reference  B站 Stable Diffusion Video ControlNet Stable Diffusion Models ControlNet Models  ","permalink":"https://quicksandznzn.github.io/posts/stable-diffusion/sd_01/","summary":"Case  生成一组人物IP Stable Diffusion模型ReV Animated + ControlNet模型 control_v11p_sd15_openpose    text2img - prompt\nPrompt (masterpiece, best quality, ultra-detailed), (full body:1.2, beautiful detailed face, beautiful detailed eyes, white background,simple background), 1 girl,Splatoon,cute,smile,gray blue hair,Orange sweater,light blue short skirt Negative Prompt (low quality:1.3),(worst quality:1.3)   ControlNet骨架图片\n   效果图片\n   Reference  B站 Stable Diffusion Video ControlNet Stable Diffusion Models ControlNet Models  ","title":"Stable Diffusion"},{"content":"FFmpeg官方文档 https://ffmpeg.org/ffmpeg-all.html\nhttps://ffmpeg.org/ffmpeg.html\n视频信息 ffmpeg -i input.mp4 Metadata: major_brand : mp42 minor_version : 0 compatible_brands: mp42mp41 creation_time : 2022-01-12T11:23:45.000000Z Duration: 00:00:59.52, start: 0.000000, bitrate: 12123 kb/s Stream #0:0[0x1](eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920 [SAR 1:1 DAR 9:16], 11802 kb/s, 25 fps, 25 tbr, 25k tbn (default) Metadata: creation_time : 2022-01-12T11:23:45.000000Z handler_name : ?Mainconcept Video Media Handler vendor_id : [0][0][0][0] encoder : AVC Coding Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 317 kb/s (default) Metadata: creation_time : 2022-01-12T11:23:54.000000Z handler_name : #Mainconcept MP4 Sound Media Handler vendor_id : [0][0][0][0]  Metadata  Stream #0:0 Video  视频h264编码 yuv420p存储格式 分辨率 1080x1920 采样纵横比 SAR 1:1 显示宽高比 DAR 9:16 码率 11802 kb/s 平均帧率 25 fps 帧率 该参数倾向于一个基准，往往tbr跟fps相同 25 tbr 视频流 timebase 25k tbn   Stream #0:1 Audio  音频aac编码 采样率 48000Hz 声道是立体声 stereo 重采样 fltp格式 码率 317 kb/s     视频大小描述  视频文件大小：(11802 + 317) * 59.52 / 8 | (音频码率 + 视频码率) x 时长 / 8 码率：视频文件大小 * 8 / 时长 (秒)    Command Line (视频基于H.264Encode) 压缩 Reference    画质 视频分辨率 H.264转码码率 H.265转码码率（比H.264下降30%）     流畅（360P） 640*360 400Kbps 280Kbps   标清（480P） 854*480 600Kbps 420Kbps   高清（720P） 1280*720 1000Kbps 700Kbps   超清（1080P） 1920*1080 2000Kbps 1400Kbps   2K 2560*1440 7000Kbps 4900Kbps   4K 3840*2160 8000Kbps 5600Kbps    # 固定目标码率模式 # 压缩视频码率为 3096k 35 fps 视频采用h264编码 音频采用aac编码 # -threads 核心线程数 (auto,0) 默认为auto # -b:v 视频码率 b=bit rate v=video 3096 kbit/s # -r 帧率 r=frame rate 35 fps # -c:v 视频编码 c=codec v=video libx264=h264 # -acodec 音频编码 a=audio aac # -y 直接覆盖文件不用询问 ffmpeg -y -threads 0 -i input.mp4 -b:v 3096k -r 35 -c:v libx264 -acodec aac result.mp4 # 参考下面几篇文章 讲解很棒 # 恒定速率因子模式 crf # -crf 取值范围 0-51 # https://trac.ffmpeg.org/wiki/Encode/H.264 # https://www.cnblogs.com/dhcn/p/7130474.html # https://www.cnblogs.com/dhcn/p/7130474.html ffmpeg -y -i input.mp4 -c:v libx264 -crf 28 -acodec aac result.mp4 推流 # rtmp推流 隐藏banner concat拼接多个视频  # -stream_loop -1 循环推流 # video_list.txt 格式 # file \u0026#39;1.mp4\u0026#39; # file \u0026#39;2.mp4\u0026#39; ffmpeg -hide_banner -safe 0 -re -stream_loop -1 -f concat -i video_list.txt -c:v libx264 -c:a aac -f flv rtmp://127.0.0.1 转码 mov转mp4 ffmpeg -y -i input.mov -c:v libx264 result.mp4 裁剪 # 两个例子都是从0秒开始截一张图 # -ss 从0秒开始 把-ss 0 放到第一个参数的位置，速度比放到放到其他位置快  # -vframes 截图帧数 或者使用-t : 截图时长 seconds # -s 图片宽高比 ffmpeg -ss 0 -i input.mp4 -r 1 -vframes 1 -s 352x240 -y result%d.jpg ffmpeg -ss 00:00:00 -i input.mp4 -r 1 -t 1 -y result%d.jpg # 截音频 0-10秒 ffmpeg -ss 00:00:00 -i input.mp3 -to 00:00:10 -acodec copy result.mp3 # 截音频 10秒后 ffmpeg -ss 00:00:10 -i input.mp3 -acodec copy result.mp3 视频转图片(每隔一秒截取一张图) # -q:v Quality factor. Lower is better. ffmpeg -y -i input.mp4 -f image2 -r 1 -q:v 10 result%3d.jpg 音视频倍速 # 2倍速  ffmpeg -y -i input.mp4 -filter:v \u0026#34;setpts=0.5*PTS\u0026#34; -filter:a \u0026#34;atempo=2.0\u0026#34; result.mp4 视频添加水印 # x和y表示水印在视频中的位置，视频左上角坐标为(0,0)，向右向下延伸 ffmpeg -y -i input.mp4 -i watermark.png -filter_complex \u0026#34;overlay=x=0:y=0\u0026#34; result.mp4 # main_w(W)：主画面的宽度 # main_h(H)：主画面的高度 # overlay_w(w)：水印宽度 # overlay_h(h)：水印高度 # overlay=x=W-w:y=0 右上角 # overlay=x=0:y=H-h 左下角  # 水印位置的写法： # 绝对位置：50:50 以左上角为0:0定位 # 图片水印 # 左下角50x50：x=50:y=main_h-overlay_h-50 # 左上角50x50：x=50:y=50 # 右下角50x50：x=main_w-overlay_w-50:y=main_h-overlay_h-50 # 右上角50x50：x=main_w-overlay_w-50:y=50 # 顶部居中：x=main_w/2-overlay_w/2:y=50 # 底部居中：x=main_w/2-overlay_w/2:y=main_h-overlay_h-50 # 左垂直居中：x=50:y=main_h/2-overlay_h/2 # 右垂直居中：x=main_w-overlay_w-50:y=main_h/2-overlay_h/2 # 完全居中：x=main_w/2-overlay_w/2:y=main_h/2-overlay_h/2 # 文字水印：  # overlay_w 换成 text_w # overlay_h 换成 line_h # 顶部居中：x=main_w/2-text_w/2:y=50 # 底部居中：x=main_w/2-text_w/2:y=main_h-line_h-50 # 左垂直居中：x=50:y=main_h/2-line_h/2 # 右垂直居中：x=main_w-text_w-50:y=main_h/2-line_h/2 # 完全居中：x=main_w/2-text_w/2:y=main_h/2-line_h/2 ffmpeg -y -i input.mp4 -i watermark.png -filter_complex \u0026#34;overlay=x=0:y=H-h\u0026#34; result.mp4 # gif水印 # -ignore_loop为0，让gif保持循环播放 # -shortest 将输出文件的时长设置为第一个视频文件的时长，如果不设置，你会发现命令会一直执行根本不会停下来，因为gif图的循环是无限的 ffmpeg -y -i input.mp4 -ignore_loop 0 -i watermark.gif -filter_complex overlay -shortest result.mp4 # 左上 左下 两个水印 ffmpeg -y -i input.mp4 -i watermark.png -i watermark2.png -filter_complex \u0026#34;overlay=x=0:y=0,overlay=x=0:y=H-h\u0026#34; result.mp4 # 水印显示5秒，5秒后消失  ffmpeg -y -i input.mp4 -i watermark.png -filter_complex \u0026#34;overlay=enable=\u0026#39;lte(t,5)\u0026#39;\u0026#34; result.mp4 # 第一个水印显示4秒后消失，2秒后第二个水印显示4秒后消失。 ffmpeg -y -i input.mp4 -i watermark.png -i watermark2.png -filter_complex \u0026#34;overlay=enable=\u0026#39;lte(mod(t,10),4)\u0026#39;,overlay=enable=\u0026#39;gt(mod(t,10),6)\u0026#39;\u0026#34; result.mp4 # 让水印每秒向右移动20像素，直到消失 ffmpeg -y -i input.mp4 -ignore_loop 0 -i watermark.gif -lavfi \u0026#34;overlay=x=t*20\u0026#34; -shortest result.mp4 # 让水印一直旋转 ffmpeg -y -i input.mp4 -loop 1 -i watermark.png -lavfi \u0026#34;[1:v]format=rgba,rotate=\u0026#39;PI/2*t:c=0x00000000:ow=hypot(iw,ih):oh=ow\u0026#39;[out];[0:v][out]overlay=10:10\u0026#34; -shortest result.mp4 # 去除水印 # x —— 水印横坐标 # y —— 水印纵坐标 # w　——　水印宽 # ｈ——　水印高 ffmpeg -y -i input.mp4 -vf \u0026#34;delogo=x=x:y=y:w=w:h=h\u0026#34; result.mp4 Reference  https://www.cnblogs.com/anfeio/p/3712218.html https://segmentfault.com/a/1190000040216980 https://www.cnblogs.com/daner1257/p/14626348.html  ","permalink":"https://quicksandznzn.github.io/posts/media/ffmpeg/","summary":"FFmpeg官方文档 https://ffmpeg.org/ffmpeg-all.html\nhttps://ffmpeg.org/ffmpeg.html\n视频信息 ffmpeg -i input.mp4 Metadata: major_brand : mp42 minor_version : 0 compatible_brands: mp42mp41 creation_time : 2022-01-12T11:23:45.000000Z Duration: 00:00:59.52, start: 0.000000, bitrate: 12123 kb/s Stream #0:0[0x1](eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920 [SAR 1:1 DAR 9:16], 11802 kb/s, 25 fps, 25 tbr, 25k tbn (default) Metadata: creation_time : 2022-01-12T11:23:45.000000Z handler_name : ?Mainconcept Video Media Handler vendor_id : [0][0][0][0] encoder : AVC Coding Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 317 kb/s (default) Metadata: creation_time : 2022-01-12T11:23:54.","title":"FFmpeg"},{"content":"Elasticsearch  ","permalink":"https://quicksandznzn.github.io/posts/search/elasticsearch_5.1.2/","summary":"Elasticsearch  ","title":"Elasticsearch"},{"content":"Scrapy  ","permalink":"https://quicksandznzn.github.io/posts/crawler/scrapy/","summary":"Scrapy  ","title":"Scrapy"},{"content":"How is the network connected  ","permalink":"https://quicksandznzn.github.io/posts/network/how_is_the_network_connected/","summary":"How is the network connected  ","title":"网络是怎样连接的"},{"content":"初始化将参数配置追加到Environment spring.factories\norg.springframework.cloud.bootstrap.BootstrapConfiguration=\\ com.alibaba.cloud.nacos.NacosConfigBootstrapConfiguration public class NacosConfigBootstrapConfiguration { // 初始化Nacos配置信息  @Bean @ConditionalOnMissingBean public NacosConfigProperties nacosConfigProperties() { return new NacosConfigProperties(); } // 初始化NacosConfigService  @Bean @ConditionalOnMissingBean public NacosConfigManager nacosConfigManager( NacosConfigProperties nacosConfigProperties) { return new NacosConfigManager(nacosConfigProperties); } // 从Nacos加载远程配置文件  @Bean public NacosPropertySourceLocator nacosPropertySourceLocator( NacosConfigManager nacosConfigManager) { return new NacosPropertySourceLocator(nacosConfigManager); } } public class NacosPropertySourceLocator implements PropertySourceLocator { @Override public PropertySource\u0026lt;?\u0026gt; locate(Environment env) { nacosConfigProperties.setEnvironment(env); ConfigService configService = nacosConfigManager.getConfigService(); if (null == configService) { log.warn(\u0026#34;no instance of config service found, can\u0026#39;t load config from nacos\u0026#34;); return null; } long timeout = nacosConfigProperties.getTimeout(); nacosPropertySourceBuilder = new NacosPropertySourceBuilder(configService, timeout); String name = nacosConfigProperties.getName(); String dataIdPrefix = nacosConfigProperties.getPrefix(); if (StringUtils.isEmpty(dataIdPrefix)) { dataIdPrefix = name; } if (StringUtils.isEmpty(dataIdPrefix)) { dataIdPrefix = env.getProperty(\u0026#34;spring.application.name\u0026#34;); } CompositePropertySource composite = new CompositePropertySource( NACOS_PROPERTY_SOURCE_NAME); // 优先级 本应用配置\u0026gt;扩展配置\u0026gt;共享配置 \t// 加载共享配置  loadSharedConfiguration(composite); // 加载扩展配置  loadExtConfiguration(composite); // 加载本应用配置  loadApplicationConfiguration(composite, dataIdPrefix, nacosConfigProperties, env); return composite; } 三类配置的加载源码主要逻辑是从NacosConfigService.getConfigInner方法根据dataId和group远程获取配置（/v1/cs/configs），存本地快照\nNacos配置修改动态刷新 初始化NacosContextRefresher给所有data-id添加监听器 spring.factories\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.alibaba.cloud.nacos.NacosConfigAutoConfiguration public class NacosConfigAutoConfiguration { // 初始化NacosContextRefresher  @Bean public NacosContextRefresher nacosContextRefresher( NacosConfigManager nacosConfigManager, NacosRefreshHistory nacosRefreshHistory) { // Consider that it is not necessary to be compatible with the previous  // configuration  // and use the new configuration if necessary.  return new NacosContextRefresher(nacosConfigManager, nacosRefreshHistory); } } public class NacosContextRefresher implements ApplicationListener\u0026lt;ApplicationReadyEvent\u0026gt;, ApplicationContextAware { // 遍历所有data-id添加监听器  /** * register Nacos Listeners. */ private void registerNacosListenersForApplications() { if (isRefreshEnabled()) { for (NacosPropertySource propertySource : NacosPropertySourceRepository .getAll()) { if (!propertySource.isRefreshable()) { continue; } String dataId = propertySource.getDataId(); registerNacosListener(propertySource.getGroup(), dataId); } } } // 有变化发送RefreshEvent事件  private void registerNacosListener(final String groupKey, final String dataKey) { String key = NacosPropertySourceRepository.getMapKey(dataKey, groupKey); Listener listener = listenerMap.computeIfAbsent(key, lst -\u0026gt; new AbstractSharedListener() { @Override public void innerReceive(String dataId, String group, String configInfo) { refreshCountIncrement(); nacosRefreshHistory.addRefreshRecord(dataId, group, configInfo); // todo feature: support single refresh for listening  applicationContext.publishEvent( new RefreshEvent(this, null, \u0026#34;Refresh Nacos config\u0026#34;)); if (log.isDebugEnabled()) { log.debug(String.format( \u0026#34;Refresh Nacos config group=%s,dataId=%s,configInfo=%s\u0026#34;, group, dataId, configInfo)); } } }); try { configService.addListener(dataKey, groupKey, listener); } catch (NacosException e) { log.warn(String.format( \u0026#34;register fail for nacos listener ,dataId=[%s],group=[%s]\u0026#34;, dataKey, groupKey), e); } } } 客户端长轮询拉取Nacos配置 初始化NacosConfigService的时候会初始化ClientWorker\npublic NacosConfigService(Properties properties) throws NacosException { ValidatorUtils.checkInitParam(properties); String encodeTmp = properties.getProperty(PropertyKeyConst.ENCODE); if (StringUtils.isBlank(encodeTmp)) { this.encode = Constants.ENCODE; } else { this.encode = encodeTmp.trim(); } initNamespace(properties); this.agent = new MetricsHttpAgent(new ServerHttpAgent(properties)); this.agent.start(); // 初始化ClientWorker  this.worker = new ClientWorker(this.agent, this.configFilterChainManager, properties); } public ClientWorker(final HttpAgent agent, final ConfigFilterChainManager configFilterChainManager, final Properties properties) { // 初始化单线程线程池，每10MS执行一次checkConfigInfo()  this.executor.scheduleWithFixedDelay(new Runnable() { @Override public void run() { try { checkConfigInfo(); } catch (Throwable e) { LOGGER.error(\u0026#34;[\u0026#34; + agent.getName() + \u0026#34;] [sub-check] rotate check error\u0026#34;, e); } } }, 1L, 10L, TimeUnit.MILLISECONDS); } 执行LongPollingRunnable\nclass LongPollingRunnable implements Runnable { private final int taskId; public LongPollingRunnable(int taskId) { this.taskId = taskId; } @Override public void run() { List\u0026lt;CacheData\u0026gt; cacheDatas = new ArrayList\u0026lt;CacheData\u0026gt;(); List\u0026lt;String\u0026gt; inInitializingCacheList = new ArrayList\u0026lt;String\u0026gt;(); try { // 检查本地配置  // check failover config  for (CacheData cacheData : cacheMap.values()) { if (cacheData.getTaskId() == taskId) { cacheDatas.add(cacheData); try { checkLocalConfig(cacheData); if (cacheData.isUseLocalConfigInfo()) { cacheData.checkListenerMd5(); } } catch (Exception e) { LOGGER.error(\u0026#34;get local config info error\u0026#34;, e); } } } // 长轮询-根据dataId和group 服务端获取配置(/v1/cs/configs/listener)  // 如果有变化返回group  // check server config  List\u0026lt;String\u0026gt; changedGroupKeys = checkUpdateDataIds(cacheDatas, inInitializingCacheList); if (!CollectionUtils.isEmpty(changedGroupKeys)) { LOGGER.info(\u0026#34;get changedGroupKeys:\u0026#34; + changedGroupKeys); } for (String groupKey : changedGroupKeys) { String[] key = GroupKey.parseKey(groupKey); String dataId = key[0]; String group = key[1]; String tenant = null; if (key.length == 3) { tenant = key[2]; } try { // 去服务端获取最新的配置更新本地数据cacheMap  String[] ct = getServerConfig(dataId, group, tenant, 3000L); CacheData cache = cacheMap.get(GroupKey.getKeyTenant(dataId, group, tenant)); cache.setContent(ct[0]); if (null != ct[1]) { cache.setType(ct[1]); } LOGGER.info(\u0026#34;[{}] [data-received] dataId={}, group={}, tenant={}, md5={}, content={}, type={}\u0026#34;, agent.getName(), dataId, group, tenant, cache.getMd5(), ContentUtils.truncateContent(ct[0]), ct[1]); } catch (NacosException ioe) { String message = String .format(\u0026#34;[%s] [get-update] get changed config exception. dataId=%s, group=%s, tenant=%s\u0026#34;, agent.getName(), dataId, group, tenant); LOGGER.error(message, ioe); } } for (CacheData cacheData : cacheDatas) { if (!cacheData.isInitializing() || inInitializingCacheList .contains(GroupKey.getKeyTenant(cacheData.dataId, cacheData.group, cacheData.tenant))) { // 遍历listeners，取到NacosContextRefresher注册的listener，执行innerReceive方法，发送RefreshEvent事件  cacheData.checkListenerMd5(); cacheData.setInitializing(false); } } inInitializingCacheList.clear(); executorService.execute(this); } catch (Throwable e) { // If the rotation training task is abnormal, the next execution time of the task will be punished  LOGGER.error(\u0026#34;longPolling error : \u0026#34;, e); executorService.schedule(this, taskPenaltyTime, TimeUnit.MILLISECONDS); } } }\t服务端长轮询逻辑 public String doPollingConfig(HttpServletRequest request, HttpServletResponse response, Map\u0026lt;String, String\u0026gt; clientMd5Map, int probeRequestSize) throws IOException { // Long polling.  // 判断是否是长轮询  if (LongPollingService.isSupportLongPolling(request)) { longPollingService.addLongPollingClient(request, response, clientMd5Map, probeRequestSize); return HttpServletResponse.SC_OK + \u0026#34;\u0026#34;; } } public void addLongPollingClient(HttpServletRequest req, HttpServletResponse rsp, Map\u0026lt;String, String\u0026gt; clientMd5Map, int probeRequestSize) { String str = req.getHeader(LongPollingService.LONG_POLLING_HEADER); String noHangUpFlag = req.getHeader(LongPollingService.LONG_POLLING_NO_HANG_UP_HEADER); String appName = req.getHeader(RequestUtil.CLIENT_APPNAME_HEADER); String tag = req.getHeader(\u0026#34;Vipserver-Tag\u0026#34;); int delayTime = SwitchService.getSwitchInteger(SwitchService.FIXED_DELAY_TIME, 500); // 长轮询时间为30s-500ms=29.5s  // Add delay time for LoadBalance, and one response is returned 500 ms in advance to avoid client timeout.  long timeout = Math.max(10000, Long.parseLong(str) - delayTime); if (isFixedPolling()) { timeout = Math.max(10000, getFixedPollingInterval()); // Do nothing but set fix polling timeout.  } else { long start = System.currentTimeMillis(); List\u0026lt;String\u0026gt; changedGroups = MD5Util.compareMd5(req, rsp, clientMd5Map); if (changedGroups.size() \u0026gt; 0) { generateResponse(req, rsp, changedGroups); LogUtil.CLIENT_LOG.info(\u0026#34;{}|{}|{}|{}|{}|{}|{}\u0026#34;, System.currentTimeMillis() - start, \u0026#34;instant\u0026#34;, RequestUtil.getRemoteIp(req), \u0026#34;polling\u0026#34;, clientMd5Map.size(), probeRequestSize, changedGroups.size()); return; } else if (noHangUpFlag != null \u0026amp;\u0026amp; noHangUpFlag.equalsIgnoreCase(TRUE_STR)) { LogUtil.CLIENT_LOG.info(\u0026#34;{}|{}|{}|{}|{}|{}|{}\u0026#34;, System.currentTimeMillis() - start, \u0026#34;nohangup\u0026#34;, RequestUtil.getRemoteIp(req), \u0026#34;polling\u0026#34;, clientMd5Map.size(), probeRequestSize, changedGroups.size()); return; } } String ip = RequestUtil.getRemoteIp(req); // Must be called by http thread, or send response.  final AsyncContext asyncContext = req.startAsync(); // AsyncContext.setTimeout() is incorrect, Control by oneself  asyncContext.setTimeout(0L); ConfigExecutor.executeLongPolling( new ClientLongPolling(asyncContext, clientMd5Map, ip, probeRequestSize, timeout, appName, tag)); } class ClientLongPolling implements Runnable { // 29.5s后执行  // 无变化从allSubs移除当前请求  // 响应客户端  @Override public void run() { asyncTimeoutFuture = ConfigExecutor.scheduleLongPolling(new Runnable() { @Override public void run() { try { getRetainIps().put(ClientLongPolling.this.ip, System.currentTimeMillis()); // Delete subsciber\u0026#39;s relations.  allSubs.remove(ClientLongPolling.this); if (isFixedPolling()) { LogUtil.CLIENT_LOG .info(\u0026#34;{}|{}|{}|{}|{}|{}\u0026#34;, (System.currentTimeMillis() - createTime), \u0026#34;fix\u0026#34;, RequestUtil.getRemoteIp((HttpServletRequest) asyncContext.getRequest()), \u0026#34;polling\u0026#34;, clientMd5Map.size(), probeRequestSize); List\u0026lt;String\u0026gt; changedGroups = MD5Util .compareMd5((HttpServletRequest) asyncContext.getRequest(), (HttpServletResponse) asyncContext.getResponse(), clientMd5Map); if (changedGroups.size() \u0026gt; 0) { sendResponse(changedGroups); } else { sendResponse(null); } } else { LogUtil.CLIENT_LOG .info(\u0026#34;{}|{}|{}|{}|{}|{}\u0026#34;, (System.currentTimeMillis() - createTime), \u0026#34;timeout\u0026#34;, RequestUtil.getRemoteIp((HttpServletRequest) asyncContext.getRequest()), \u0026#34;polling\u0026#34;, clientMd5Map.size(), probeRequestSize); sendResponse(null); } } catch (Throwable t) { LogUtil.DEFAULT_LOG.error(\u0026#34;long polling error:\u0026#34; + t.getMessage(), t.getCause()); } } }, timeoutTime, TimeUnit.MILLISECONDS); // 将当前请求加入到allSubs  allSubs.add(this); } 如果这期间发生变更，会发送 LocalDataChangeEvent事件,\npublic LongPollingService() { allSubs = new ConcurrentLinkedQueue\u0026lt;ClientLongPolling\u0026gt;(); ConfigExecutor.scheduleLongPolling(new StatTask(), 0L, 10L, TimeUnit.SECONDS); // Register LocalDataChangeEvent to NotifyCenter.  NotifyCenter.registerToPublisher(LocalDataChangeEvent.class, NotifyCenter.ringBufferSize); // 注册订阅者监听LocalDataChangeEvent事件  // Register A Subscriber to subscribe LocalDataChangeEvent.  NotifyCenter.registerSubscriber(new Subscriber() { @Override public void onEvent(Event event) { if (isFixedPolling()) { // Ignore.  } else { if (event instanceof LocalDataChangeEvent) { LocalDataChangeEvent evt = (LocalDataChangeEvent) event; ConfigExecutor.executeLongPolling(new DataChangeTask(evt.groupKey, evt.isBeta, evt.betaIps)); } } } @Override public Class\u0026lt;? extends Event\u0026gt; subscribeType() { return LocalDataChangeEvent.class; } }); } DataChangeTask接收消息遍历allSubs 找到对应的客户端请求返回给客户端结果（group+dataId）\nclass DataChangeTask implements Runnable { @Override public void run() { try { ConfigCacheService.getContentBetaMd5(groupKey); for (Iterator\u0026lt;ClientLongPolling\u0026gt; iter = allSubs.iterator(); iter.hasNext(); ) { ClientLongPolling clientSub = iter.next(); if (clientSub.clientMd5Map.containsKey(groupKey)) { // If published tag is not in the beta list, then it skipped.  if (isBeta \u0026amp;\u0026amp; !CollectionUtils.contains(betaIps, clientSub.ip)) { continue; } // If published tag is not in the tag list, then it skipped.  if (StringUtils.isNotBlank(tag) \u0026amp;\u0026amp; !tag.equals(clientSub.tag)) { continue; } getRetainIps().put(clientSub.ip, System.currentTimeMillis()); iter.remove(); // Delete subscribers\u0026#39; relationships.  LogUtil.CLIENT_LOG .info(\u0026#34;{}|{}|{}|{}|{}|{}|{}\u0026#34;, (System.currentTimeMillis() - changeTime), \u0026#34;in-advance\u0026#34;, RequestUtil .getRemoteIp((HttpServletRequest) clientSub.asyncContext.getRequest()), \u0026#34;polling\u0026#34;, clientSub.clientMd5Map.size(), clientSub.probeRequestSize, groupKey); // 会cancelasyncTimeoutFuture  // 响应客户端变化的group  clientSub.sendResponse(Arrays.asList(groupKey)); } } } catch (Throwable t) { LogUtil.DEFAULT_LOG.error(\u0026#34;data change error: {}\u0026#34;, ExceptionUtil.getStackTrace(t)); } } Spring RefreshEvent事件刷新配置文件解析 RefreshEvent监听者\npublic class RefreshEventListener implements SmartApplicationListener { public void handle(RefreshEvent event) { if (this.ready.get()) { // don\u0026#39;t handle events before app is ready  log.debug(\u0026#34;Event received \u0026#34; + event.getEventDesc()); // 执行刷新  Set\u0026lt;String\u0026gt; keys = this.refresh.refresh(); log.info(\u0026#34;Refresh keys changed: \u0026#34; + keys); } } } public abstract class ContextRefresher { private RefreshScope scope; protected RefreshScope getScope() { return this.scope; } public synchronized Set\u0026lt;String\u0026gt; refresh() { // 发送EnvironmentChangeEvent事件  // 监听该事件的监听器多个，只需要关注LoggingBebinde和ConfigurationPropertiesRebinder  // ConfigurationPropertiesRebinder.rebind() 销毁原有的Bean,在重新初始化Bean  // LoggingBebinde通过LoggingSystem重新设置日志级别  Set\u0026lt;String\u0026gt; keys = refreshEnvironment(); // 刷新@RefreshScope注解的类  // 对于@RefreshScope注解的类，当每次被调用的时候，都会进行初始化，同时采用懒代理的方法，将作用域充当\t初始值的缓存，当缓存存在时，不会再进行初始化。因此，对于刷新@RefreshScope注解的类，只需要将其缓存\t进行清空，则在下一次访问的时候，依赖新的配置源，将生成新的缓存  this.scope.refreshAll(); return keys; } Tips: Nacos2.0+采用grpc替换长轮询，后面分享\n","permalink":"https://quicksandznzn.github.io/posts/springcloud/alibaba/nacos/spring-cloud-starter-alibaba-nacos-config/","summary":"初始化将参数配置追加到Environment spring.factories\norg.springframework.cloud.bootstrap.BootstrapConfiguration=\\ com.alibaba.cloud.nacos.NacosConfigBootstrapConfiguration public class NacosConfigBootstrapConfiguration { // 初始化Nacos配置信息  @Bean @ConditionalOnMissingBean public NacosConfigProperties nacosConfigProperties() { return new NacosConfigProperties(); } // 初始化NacosConfigService  @Bean @ConditionalOnMissingBean public NacosConfigManager nacosConfigManager( NacosConfigProperties nacosConfigProperties) { return new NacosConfigManager(nacosConfigProperties); } // 从Nacos加载远程配置文件  @Bean public NacosPropertySourceLocator nacosPropertySourceLocator( NacosConfigManager nacosConfigManager) { return new NacosPropertySourceLocator(nacosConfigManager); } } public class NacosPropertySourceLocator implements PropertySourceLocator { @Override public PropertySource\u0026lt;?\u0026gt; locate(Environment env) { nacosConfigProperties.setEnvironment(env); ConfigService configService = nacosConfigManager.getConfigService(); if (null == configService) { log.","title":"spring-cloud-starter-alibaba-nacos-config源码分析"},{"content":"Q 准备工作   Frida\n frida-15.1.14-py3.8-macosx-10.9-x86_64.egg 放到~目录（pip install frida报错时会出现目录地址） pip install frida pip install frida-tools 网易mumu frida-server-15.1.14-android-x86_64 需要确认底层架构，网易mumu是x86_64 FRIDA-DEXDump    脱壳  adb push ~/Downloads/frida-server-15.1.14-android-x86_64 /data/local adb shell cd /data/local chmod 777 frida-server-15.1.14-android-x86_64 ./frida-server-15.1.14-android-x86_64 通过网易mumu打开APP 通过FRIDA-DEXDump执行 python main.py  done !  ","permalink":"https://quicksandznzn.github.io/posts/crawler/crawler_frida_hook/","summary":"Q 准备工作   Frida\n frida-15.1.14-py3.8-macosx-10.9-x86_64.egg 放到~目录（pip install frida报错时会出现目录地址） pip install frida pip install frida-tools 网易mumu frida-server-15.1.14-android-x86_64 需要确认底层架构，网易mumu是x86_64 FRIDA-DEXDump    脱壳  adb push ~/Downloads/frida-server-15.1.14-android-x86_64 /data/local adb shell cd /data/local chmod 777 frida-server-15.1.14-android-x86_64 ./frida-server-15.1.14-android-x86_64 通过网易mumu打开APP 通过FRIDA-DEXDump执行 python main.py  done !  ","title":"Apk脱壳"},{"content":"准备工作  网易mumu模拟器  Root Explorer APK ES文件浏览器 微信   小程序反编译工具  破解  打开微信搜索对应的小程序 最好提前清空微信小程序缓存这样比较好找到对应的小程序 通过Root Explorer找到对应目录 /data/data/com.tencent.mm/MicroMsg/7e0c9d2b7278c1fac318e91eaeae4c0f/appbrand/pkg  通过wxappUnpacker bingo.sh 反编译得到源码  ","permalink":"https://quicksandznzn.github.io/posts/crawler/crawler_mini_program_crack/","summary":"准备工作  网易mumu模拟器  Root Explorer APK ES文件浏览器 微信   小程序反编译工具  破解  打开微信搜索对应的小程序 最好提前清空微信小程序缓存这样比较好找到对应的小程序 通过Root Explorer找到对应目录 /data/data/com.tencent.mm/MicroMsg/7e0c9d2b7278c1fac318e91eaeae4c0f/appbrand/pkg  通过wxappUnpacker bingo.sh 反编译得到源码  ","title":"微信小程序反编译"},{"content":"页面分析  view page source  \u0026lt;span class=\u0026#34;gzfont\u0026#34; data-v-48736255\u0026gt;\u0026amp;#58928;\u0026amp;#59854;\u0026amp;#58397;\u0026amp;#60492;-\u0026amp;#59854;\u0026amp;#59246;\u0026lt;/span\u0026gt;  可以看到以上的字体是有加密的 我们通过gzfont这个class去css中寻找  .gzfont { font-family: gzfont } @font-face { font-family: \u0026#34;gzfont\u0026#34;; src: url(https://example.woff2) format(\u0026#34;woff\u0026#34;); font-weight: 400; font-style: normal }  src中的url就是字体文件的下载地址  字体文件解析  经过多次刷新发现css里面的字体文件是不会变的，我们只需要把字体文件解析出来匹配好对应关系即可 FontEditor在线浏览字体文件   通过python的TTFont把字体文件解析成XML  from fontTools.ttLib import TTFont font = TTFont(\u0026#39;/Users/zn/Downloads/font.woff2\u0026#39;) font.saveXML(\u0026#39;font.xml\u0026#39;)  一个GlyphID里面的name对应一个TTGlyph对象，它是用来绘制一个字  \u0026lt;GlyphOrder\u0026gt; \u0026lt;!-- The \u0026#39;id\u0026#39; attribute is only for humans; it is ignored when parsed. --\u0026gt; \u0026lt;GlyphID id=\u0026#34;0\u0026#34; name=\u0026#34;.notdef\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;1\u0026#34; name=\u0026#34;.null\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;2\u0026#34; name=\u0026#34;nonmarkingreturn\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;3\u0026#34; name=\u0026#34;x\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;4\u0026#34; name=\u0026#34;uniE1D0\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;5\u0026#34; name=\u0026#34;uniE325\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;6\u0026#34; name=\u0026#34;uniE41D\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;7\u0026#34; name=\u0026#34;uniE4D9\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;8\u0026#34; name=\u0026#34;uniE52E\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;9\u0026#34; name=\u0026#34;uniE630\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;10\u0026#34; name=\u0026#34;uniE76E\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;11\u0026#34; name=\u0026#34;uniE891\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;12\u0026#34; name=\u0026#34;uniE9CE\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;13\u0026#34; name=\u0026#34;uniEAF2\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;14\u0026#34; name=\u0026#34;uniEC4C\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;15\u0026#34; name=\u0026#34;uniF7C2\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;16\u0026#34; name=\u0026#34;uniF88A\u0026#34;/\u0026gt; \u0026lt;/GlyphOrder\u0026gt; \u0026lt;TTGlyph name=\u0026#34;uniEAF2\u0026#34; xMin=\u0026#34;43\u0026#34; yMin=\u0026#34;-40\u0026#34; xMax=\u0026#34;523\u0026#34; yMax=\u0026#34;716\u0026#34;\u0026gt; \u0026lt;contour\u0026gt; \u0026lt;pt x=\u0026#34;133\u0026#34; y=\u0026#34;180\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;148\u0026#34; y=\u0026#34;103\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;185\u0026#34; y=\u0026#34;69\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;221\u0026#34; y=\u0026#34;38\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;276\u0026#34; y=\u0026#34;35\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;326\u0026#34; y=\u0026#34;35\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;384\u0026#34; y=\u0026#34;78\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;427\u0026#34; y=\u0026#34;123\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;427\u0026#34; y=\u0026#34;250\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;387\u0026#34; y=\u0026#34;290\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;345\u0026#34; y=\u0026#34;331\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;284\u0026#34; y=\u0026#34;331\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;257\u0026#34; y=\u0026#34;331\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;220\u0026#34; y=\u0026#34;321\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;230\u0026#34; y=\u0026#34;406\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;236\u0026#34; y=\u0026#34;400\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;239\u0026#34; y=\u0026#34;399\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;254\u0026#34; y=\u0026#34;399\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;245\u0026#34; y=\u0026#34;399\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;303\u0026#34; y=\u0026#34;411\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;348\u0026#34; y=\u0026#34;428\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;394\u0026#34; y=\u0026#34;459\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;394\u0026#34; y=\u0026#34;524\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;395\u0026#34; y=\u0026#34;579\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;361\u0026#34; y=\u0026#34;604\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;330\u0026#34; y=\u0026#34;635\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;274\u0026#34; y=\u0026#34;635\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;222\u0026#34; y=\u0026#34;635\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;195\u0026#34; y=\u0026#34;604\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;153\u0026#34; y=\u0026#34;572\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;142\u0026#34; y=\u0026#34;504\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;52\u0026#34; y=\u0026#34;520\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;69\u0026#34; y=\u0026#34;612\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;127\u0026#34; y=\u0026#34;660\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;186\u0026#34; y=\u0026#34;699\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;272\u0026#34; y=\u0026#34;716\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;326\u0026#34; y=\u0026#34;710\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;383\u0026#34; y=\u0026#34;683\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;433\u0026#34; y=\u0026#34;659\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;487\u0026#34; y=\u0026#34;569\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;487\u0026#34; y=\u0026#34;470\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;462\u0026#34; y=\u0026#34;432\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;445\u0026#34; y=\u0026#34;394\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;371\u0026#34; y=\u0026#34;371\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;451\u0026#34; y=\u0026#34;356\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;487\u0026#34; y=\u0026#34;309\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;519\u0026#34; y=\u0026#34;247\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;523\u0026#34; y=\u0026#34;190\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;523\u0026#34; y=\u0026#34;95\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;383\u0026#34; y=\u0026#34;-40\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;276\u0026#34; y=\u0026#34;-40\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;179\u0026#34; y=\u0026#34;-40\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;116\u0026#34; y=\u0026#34;18\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;52\u0026#34; y=\u0026#34;82\u0026#34; on=\u0026#34;0\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;43\u0026#34; y=\u0026#34;155\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;pt x=\u0026#34;133\u0026#34; y=\u0026#34;174\u0026#34; on=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;/contour\u0026gt; \u0026lt;instructions/\u0026gt; \u0026lt;/TTGlyph\u0026gt;   读取CMAP code是16进制的数字 对应页面的数字值 name对应字体编码  可以得出 58928==0xe630==uniE630    \u0026lt;cmap_format_4 platformID=\u0026#34;0\u0026#34; platEncID=\u0026#34;3\u0026#34; language=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;map code=\u0026#34;0x78\u0026#34; name=\u0026#34;x\u0026#34;/\u0026gt;\u0026lt;!-- LATIN SMALL LETTER X --\u0026gt; \u0026lt;map code=\u0026#34;0xe1d0\u0026#34; name=\u0026#34;uniE1D0\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe325\u0026#34; name=\u0026#34;uniE325\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe41d\u0026#34; name=\u0026#34;uniE41D\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe4d9\u0026#34; name=\u0026#34;uniE4D9\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe52e\u0026#34; name=\u0026#34;uniE52E\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe630\u0026#34; name=\u0026#34;uniE630\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe76e\u0026#34; name=\u0026#34;uniE76E\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe891\u0026#34; name=\u0026#34;uniE891\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xe9ce\u0026#34; name=\u0026#34;uniE9CE\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xeaf2\u0026#34; name=\u0026#34;uniEAF2\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xec4c\u0026#34; name=\u0026#34;uniEC4C\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xf7c2\u0026#34; name=\u0026#34;uniF7C2\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;map code=\u0026#34;0xf88a\u0026#34; name=\u0026#34;uniF88A\u0026#34;/\u0026gt;\u0026lt;!-- ???? --\u0026gt; \u0026lt;/cmap_format_4\u0026gt;  生成对应关系如下  [ {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#57808;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE1D0\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;7\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#58149;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE325\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;4\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#58397;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE41D\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;1\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#58585;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE4D9\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#58670;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE52E\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;9\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#58928;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE630\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;2\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#59246;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE76E\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;8\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#59537;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE891\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;5\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#59854;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniE9CE\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;0\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#60146;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniEAF2\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;3\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#60492;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniEC4C\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;6\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#63426;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniF7C2\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;\u0026#39;}, {\u0026#39;id\u0026#39;: \u0026#39;\u0026amp;#63626;\u0026#39;, \u0026#39;uni\u0026#39;: \u0026#39;uniF88A\u0026#39;, \u0026#39;num\u0026#39;: \u0026#39;7\u0026#39;} ] ","permalink":"https://quicksandznzn.github.io/posts/crawler/crawler_font_crack/","summary":"页面分析  view page source  \u0026lt;span class=\u0026#34;gzfont\u0026#34; data-v-48736255\u0026gt;\u0026amp;#58928;\u0026amp;#59854;\u0026amp;#58397;\u0026amp;#60492;-\u0026amp;#59854;\u0026amp;#59246;\u0026lt;/span\u0026gt;  可以看到以上的字体是有加密的 我们通过gzfont这个class去css中寻找  .gzfont { font-family: gzfont } @font-face { font-family: \u0026#34;gzfont\u0026#34;; src: url(https://example.woff2) format(\u0026#34;woff\u0026#34;); font-weight: 400; font-style: normal }  src中的url就是字体文件的下载地址  字体文件解析  经过多次刷新发现css里面的字体文件是不会变的，我们只需要把字体文件解析出来匹配好对应关系即可 FontEditor在线浏览字体文件   通过python的TTFont把字体文件解析成XML  from fontTools.ttLib import TTFont font = TTFont(\u0026#39;/Users/zn/Downloads/font.woff2\u0026#39;) font.saveXML(\u0026#39;font.xml\u0026#39;)  一个GlyphID里面的name对应一个TTGlyph对象，它是用来绘制一个字  \u0026lt;GlyphOrder\u0026gt; \u0026lt;!-- The \u0026#39;id\u0026#39; attribute is only for humans; it is ignored when parsed. --\u0026gt; \u0026lt;GlyphID id=\u0026#34;0\u0026#34; name=\u0026#34;.notdef\u0026#34;/\u0026gt; \u0026lt;GlyphID id=\u0026#34;1\u0026#34; name=\u0026#34;.","title":"字体加密破解"},{"content":"跨域概述  跨域就指着协议，域名，端口不一致，出于安全考虑，跨域的资源之间是无法交互的。简单说就是协议不通，域名不通，端口不同都会产生跨域问题  跨源资源共享（CORS)  跨源资源共享 (CORS) （或通俗地译为跨域资源共享）是一种基于HTTP 头的机制，该机制通过允许服务器标示除了它自己以外的其它origin（域，协议和端口），这样浏览器可以访问加载这些资源。跨源资源共享还通过一种机制来检查服务器是否会允许要发送的真实请求，该机制通过浏览器发起一个到服务器托管的跨源资源的\u0026quot;预检\u0026quot;请求。在预检中，浏览器发送的头中标示有HTTP方法和真实请求中会用到的头  遇到的问题   The \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header contains multiple values \u0026lsquo;, \u0026lsquo;, but ..\n  单个项目解决跨域问题\n  @Configuration public class WebMvcConfigurer extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;) .allowCredentials(true) .allowedHeaders(\u0026#34;*\u0026#34;) .allowedOrigins(\u0026#34;*\u0026#34;) .allowedMethods(\u0026#34;*\u0026#34;); } }  因为我们用Zuul做网关，在网关层也配置了CORS跨域问题解决，这样就会导致遇到上述错误 解决方法  在Zuul配置文件添加    sensitiveHeaders: Access-Control-Allow-Origin,Access-Control-Allow-Methods,Access-Control-Allow-Credentials ","permalink":"https://quicksandznzn.github.io/posts/gateway/zuul_cross_domain/","summary":"跨域概述  跨域就指着协议，域名，端口不一致，出于安全考虑，跨域的资源之间是无法交互的。简单说就是协议不通，域名不通，端口不同都会产生跨域问题  跨源资源共享（CORS)  跨源资源共享 (CORS) （或通俗地译为跨域资源共享）是一种基于HTTP 头的机制，该机制通过允许服务器标示除了它自己以外的其它origin（域，协议和端口），这样浏览器可以访问加载这些资源。跨源资源共享还通过一种机制来检查服务器是否会允许要发送的真实请求，该机制通过浏览器发起一个到服务器托管的跨源资源的\u0026quot;预检\u0026quot;请求。在预检中，浏览器发送的头中标示有HTTP方法和真实请求中会用到的头  遇到的问题   The \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header contains multiple values \u0026lsquo;, \u0026lsquo;, but ..\n  单个项目解决跨域问题\n  @Configuration public class WebMvcConfigurer extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;) .allowCredentials(true) .allowedHeaders(\u0026#34;*\u0026#34;) .allowedOrigins(\u0026#34;*\u0026#34;) .allowedMethods(\u0026#34;*\u0026#34;); } }  因为我们用Zuul做网关，在网关层也配置了CORS跨域问题解决，这样就会导致遇到上述错误 解决方法  在Zuul配置文件添加    sensitiveHeaders: Access-Control-Allow-Origin,Access-Control-Allow-Methods,Access-Control-Allow-Credentials ","title":"Zuul网关跨域问题"},{"content":"Rehash  rehash执行条件  关键说明  负载因子:：load_factor = ht[0].used / ht[0].size BGSAVE:：fork一个子进程来创建RDB文件，父进程可以继续处理命令请求 BGREWRITEAOF：AOF重写缓冲区,由于redis是单进程的，为了不在进行重写时阻塞服务，redis使用了子进程的方式进行AOF重写 redis中每次开始执行aof文件重写或者开始生成新的RDB文件或者执行aof重写/生成RDB的子进程结束时，都会调用updateDictResizePolicy-\u0026gt;dictDisableResize函数，所以从该函数中，也可以看出来，如果当前没有子进程在执行aof文件重写或者生成RDB文件，则运行进行字典扩容；否则禁止字典扩容。   扩容  以下条件中的任意一个被满足时执行扩容  服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5     缩容  databasesCron-\u0026gt;tryResizeHashTables函数检查用于保存键值对的redis数据库字典是否需要缩容 最小size是4 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作     rehash执行过程  为字典的 ht[1] 哈希表分配空间=ht[0].used= ht[0] 当前包含的键值对数量  如果执行的是扩展操作， 那么 ht[1] 的大小为 为第一个大于等于ht[0].used * 2 的 2^n 如果执行的是收缩操作， 那么 ht[1] 的大小为为第一个大于等于 ht[0].used的 2^n   将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。    渐进式Rehash  rehash执行条件等同于Rehash 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。 rehash执行过程  为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维护一个索引计数器变量rehashidx,并将它设置为0，表示rehash工作正式开始 在rehash进行期间，每次对字段执行添加、删除、查找、更新操作的时候，程序除了执行指定的操作意外，还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值++ 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。    定时辅助rehash   虽然redis实现了在读写操作时，辅助服务器进行渐进式rehash操作，但是如果服务器比较空闲，redis数据库将很长时间内都一直使用两个哈希表。所以在redis周期函数中，如果发现有字典正在进行渐进式rehash操作，则会花费1毫秒的时间，帮助一起进行渐进式rehash操作。\n  配置 activerehashing yes\n  源码位置redis.c-\u0026gt;databasesCron-\u0026gt;server.activerehashing-\u0026gt;incrementallyRehash\n  遇到的问题  渐进式rehash避免了redis阻塞，可以说非常完美，但是由于在rehash时，需要分配一个新的hash表，在rehash期间，同时有两个hash表在使用，会使得redis内存使用量瞬间突增，在Redis 满容状态下由于Rehash会导致大量Key驱逐。 美团案例和解决方案  参考文章  https://luoming1224.github.io/2018/11/12/%5Bredis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%5Dredis%E6%B8%90%E8%BF%9B%E5%BC%8Frehash%E6%9C%BA%E5%88%B6/ https://tech.meituan.com/2018/07/27/redis-rehash-practice-optimization.html  ","permalink":"https://quicksandznzn.github.io/posts/redis/redis_rehash/","summary":"Rehash  rehash执行条件  关键说明  负载因子:：load_factor = ht[0].used / ht[0].size BGSAVE:：fork一个子进程来创建RDB文件，父进程可以继续处理命令请求 BGREWRITEAOF：AOF重写缓冲区,由于redis是单进程的，为了不在进行重写时阻塞服务，redis使用了子进程的方式进行AOF重写 redis中每次开始执行aof文件重写或者开始生成新的RDB文件或者执行aof重写/生成RDB的子进程结束时，都会调用updateDictResizePolicy-\u0026gt;dictDisableResize函数，所以从该函数中，也可以看出来，如果当前没有子进程在执行aof文件重写或者生成RDB文件，则运行进行字典扩容；否则禁止字典扩容。   扩容  以下条件中的任意一个被满足时执行扩容  服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5     缩容  databasesCron-\u0026gt;tryResizeHashTables函数检查用于保存键值对的redis数据库字典是否需要缩容 最小size是4 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作     rehash执行过程  为字典的 ht[1] 哈希表分配空间=ht[0].used= ht[0] 当前包含的键值对数量  如果执行的是扩展操作， 那么 ht[1] 的大小为 为第一个大于等于ht[0].used * 2 的 2^n 如果执行的是收缩操作， 那么 ht[1] 的大小为为第一个大于等于 ht[0].","title":"Redis Rehash"},{"content":"Redis 的两种持久化方式(RDB与AOF) RDB RDB (Redis DataBase) 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。\n RDB触发机制分为手动触发和自动触发  手动触发  SAVE命令：阻塞当前Redis服务器，知道RDB过程完成为止 BGSAVE：Redis 进程执行fork()操作创建出一个子进程，在后台完成RDB持久化的过程   自动触发 配置(redis.conf) == BGSAVE  save 900 1 //服务器在900秒之内，对数据库执行了至少1次修改 save 300 10 //服务器在300秒之内，对数据库执行了至少10修改 save 60 1000 //服务器在60秒之内，对数据库执行了至少1000修改     优势  整个 Redis 数据库将只包含一个文件，十分易于备份 性能最大化，对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大地避免服务进程执行 IO 操作 相对于 AOF，基于 RDB 数据文件来重启和恢复 Redis 会更快   劣势  无法最大限度地避免数据丢失，系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据较大时，可能会导致整个服务器停止服务数毫秒，甚至数秒    AOF AOF (Append Only File) 持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，只许追加文件但不可以改写文件，可以打开文件看到详细的操作记录\n 同步策略  appendsync always #每次有数据修改发生时都会写入AOF文件 appendsync everysec #每秒同步一次，该策略为AOF的缺省策略 appendsync no #从不同步。高效但是数据不会被持久化   优势  最大限度地避免数据丢失，默认的 everysec 策略可以记录下每秒的修改操作，但如果一秒内宕机，有数据丢失 AOF 对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。   劣势  对于同一份数据来说，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB。但是每秒同步策略的效率还是比较高的。    总结 二者选择的标准，就是愿意牺牲一些性能，换取最少的数据丢失(AOF)，还是牺牲一些数据来换取更高的性能(RDB)。实际中应该综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复\nRedis参考文章  https://marticles.github.io/2018/12/25/Redis%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/ https://github.com/redis/redis  ","permalink":"https://quicksandznzn.github.io/posts/redis/redis_data_persistence/","summary":"Redis 的两种持久化方式(RDB与AOF) RDB RDB (Redis DataBase) 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。\n RDB触发机制分为手动触发和自动触发  手动触发  SAVE命令：阻塞当前Redis服务器，知道RDB过程完成为止 BGSAVE：Redis 进程执行fork()操作创建出一个子进程，在后台完成RDB持久化的过程   自动触发 配置(redis.conf) == BGSAVE  save 900 1 //服务器在900秒之内，对数据库执行了至少1次修改 save 300 10 //服务器在300秒之内，对数据库执行了至少10修改 save 60 1000 //服务器在60秒之内，对数据库执行了至少1000修改     优势  整个 Redis 数据库将只包含一个文件，十分易于备份 性能最大化，对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大地避免服务进程执行 IO 操作 相对于 AOF，基于 RDB 数据文件来重启和恢复 Redis 会更快   劣势  无法最大限度地避免数据丢失，系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据较大时，可能会导致整个服务器停止服务数毫秒，甚至数秒    AOF AOF (Append Only File) 持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，只许追加文件但不可以改写文件，可以打开文件看到详细的操作记录","title":"Redis 持久化方式"},{"content":"数据类型及使用场景  String：缓存、计数器、分布式锁等 List：链表、队列、微博关注人时间轴列表等 Hash： 用户信息、Hash 表等 Set： 去重、赞、踩、共同好友等 Sorted Set： 访问量排行榜、点击量排行榜等  Redis Object typedef struct redisObject { unsigned type:4; // 类型  unsigned encoding:4; // 一个对象可能包含多个encoding  unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; // 引用计数 实现内存回收机制  void *ptr; // 存储的值 } robj; /* Object types */ #define OBJ_STRING 0 #define OBJ_LIST 1 #define OBJ_SET 2 #define OBJ_ZSET 3 #define OBJ_HASH 4  /* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The \u0026#39;encoding\u0026#39; field of the object * is set to one of this fields for this object. */ #define OBJ_ENCODING_RAW 0 /* Raw representation */简单动态字符串 #define OBJ_ENCODING_INT 1 /* Encoded as integer */整数类型 实际上是long #define OBJ_ENCODING_HT 2 /* Encoded as hash table */字典 hashtable #define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */是个旧的表示方式，已不再用 #define OBJ_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */是个旧的表示方式，已不再用 #define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */压缩列表 #define OBJ_ENCODING_INTSET 6 /* Encoded as intset */整数集合 #define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */跳跃表 #define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */embstr编码的简单动态字符串 #define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */quicklist 双向ziplist String 简单动态字符串 sds (sds替代C char*)\n  sds的好处:\n 可动态扩展内存。sds表示的字符串其内容可以修改，也可以追加 二进制安全（Binary Safe）。sds能存储任意二进制数据，而不仅仅是可打印字符 与传统的C语言字符串类型兼容    内部OBJ ENCODING:\n OBJ_ENCODING_RAW 最原生的表示方式。其实只有string类型才会用这个encoding值（表示成sds） OBJ_ENCODING_INT 表示成数字。实际用long表示 OBJ_ENCODING_EMBSTR 表示成一种特殊的嵌入式的sds    set命令:\n 源码object.c中的tryObjectEncoding 第1步检查，检查type。确保只对string类型的对象进行操作。 第2步检查，检查encoding。sdsEncodedObject是定义在server.h中的一个宏，确保只对OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR编码的string对象进行操作。这两种编码的string都采用sds来存储，可以尝试进一步编码处理 第3步检查，检查refcount。引用计数大于1的共享对象，在多处被引用。由于编码过程结束后robj的对象指针可能会变化（我们在前一篇介绍sdscatlen函数的时候提到过类似这种接口使用模式），这样对于引用计数大于1的对象，就需要更新所有地方的引用，这不容易做到。因此，对于计数大于1的对象不做编码处理  第一种情况：如果Redis的配置不要求运行LRU替换算法，且转成的long型数字的值又比较小（小于OBJ_SHARED_INTEGERS，在目前的实现中这个值是10000），那么会使用共享数字对象来表示。之所以这里的判断跟LRU有关，是因为LRU算法要求每个robj有不同的lru字段值，所以用了LRU就不能共享robj。shared.integers是一个长度为10000的数组，里面预存了10000个小的数字对象。这些小数字对象都是encoding = OBJ_ENCODING_INT的string robj对象。 第二种情况：如果前一步不能使用共享小对象来表示，那么将原来的robj编码成encoding = OBJ_ENCODING_INT，这时ptr字段直接存成这个long型的值。注意ptr字段本来是一个void *指针（即存储的是内存地址），因此在64位机器上有64位宽度，正好能存储一个64位的long型值。这样，除了robj本身之外，它就不再需要额外的内存空间来存储字符串值。   试图将字符串转成64位的long。64位的long所能表达的数据范围是-2^63到2^63-1，用十进制表达出来最长是20位数（包括负号），string2l如果将字符串转成long转成功了，那么会返回1并且将转好的long存到value变量里 如果字符串长度足够小（小于等于OBJ_ENCODING_EMBSTR_SIZE_LIMIT，定义为44），那么调用createEmbeddedStringObject编码成encoding = OBJ_ENCODING_EMBSTR 如果前面所有的编码尝试都没有成功（仍然是OBJ_ENCODING_RAW），且sds里空余字节过多，那么做最后一次努力，调用sds的sdsRemoveFreeSpace接口来释放空余字节    get命令\n object.c中的getDecodedObject 编码为OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR的字符串robj对象，不做变化，原封不动返回。站在使用者的角度，这两种编码没有什么区别，内部都是封装的sds。 编码为数字的字符串robj对象，将long重新转为十进制字符串的形式，然后调用createStringObject转为sds的表示。注意：这里由long转成的sds字符串长度肯定不超过20，而根据createStringObject的实现，它们肯定会被编码成OBJ_ENCODING_EMBSTR的对象    List quicklist（是一个ziplist的双向链表）\n 内部OBJ ENCODING:  OBJ_ENCODING_QUICKLIST   关键参数  list-max-ziplist-size  正值  当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项   负值  -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =\u0026gt; 1024 bytes） -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。 -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。 -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值） -4: -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。     list-compress-depth  0: 是个特殊值，表示都不压缩。这是Redis的默认值。 1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。 2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。 依此类推…     压缩算法  采用的LZF无损压缩算法 quicklist.h  typedef struct quicklistLZF { unsigned int sz; /* LZF size in bytes*/ char compressed[]; } quicklistLZF;   Hash 压缩列表+哈希表\n 内部OBJ ENCODING:  OBJ_ENCODING_HT OBJ_ENCODING_ZIPLIST   hash的底层存储有两种数据结构，一种是ziplist，另外一种是hashtable，hash对象只有同时满足以下条件，才会采用ziplist编码：  当列表元素小于hash_max_ziplist_entries:512 当列表元素的值都小于hash_max_ziplist_value:64字节    Set 哈希表+整数数组\n 内部OBJ ENCODING:  OBJ_ENCODING_HT OBJ_ENCODING_INTSET   set的底层存储有两种数据结构，intset，另外一种是hashtable，set对象只有同时满足以下条件，才会采用intset编码：  当集合元素小于set_max_intset_entries:512 当集合元素都是数字 isObjectRepresentableAsLongLong   intset是有序的 里面都是数字类型 hashtable 的key是字符串类型对象 value是null  Sorted Set 压缩列表+跳表（跳表+字典）\n 内部OBJ ENCODING:  OBJ_ENCODING_ZIPLIST OBJ_ENCODING_SKIPLIST   当集合元素大于zset_max_ziplist_entries（默认128） 或者 当集合元素值大于zset_max_ziplist_value（默认64字节）转换为跳表 可以相互转换 skiplist 编码的 Zset 底层为一个被称为 zset 的结构体，这个结构体中包含一个字典和一个跳跃表 跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。字典则保存着从 member 到 score 的映射，这样就可以用 O(1) 的复杂度来查找 member 对应的 score 值。虽然同时使用两种结构，但它们会通过指针来共享相同元素的 member 和 score，因此不会浪费额外的内存。  Redis参考文章  https://marticles.github.io/2018/12/25/Redis%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/ https://github.com/menwenjun/redis_source_annotation https://github.com/redis/redis  ","permalink":"https://quicksandznzn.github.io/posts/redis/redis_data_type/","summary":"数据类型及使用场景  String：缓存、计数器、分布式锁等 List：链表、队列、微博关注人时间轴列表等 Hash： 用户信息、Hash 表等 Set： 去重、赞、踩、共同好友等 Sorted Set： 访问量排行榜、点击量排行榜等  Redis Object typedef struct redisObject { unsigned type:4; // 类型  unsigned encoding:4; // 一个对象可能包含多个encoding  unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; // 引用计数 实现内存回收机制  void *ptr; // 存储的值 } robj; /* Object types */ #define OBJ_STRING 0 #define OBJ_LIST 1 #define OBJ_SET 2 #define OBJ_ZSET 3 #define OBJ_HASH 4  /* Objects encoding.","title":"Redis 数据类型"},{"content":"缓存雪崩  描述  大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。   解决方案  分级缓存 给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。    缓存穿透  描述  访问一个不存在的 key 时，缓存不起作用，请求会穿透到 DB ，流量大时 DB 自然就会瘫痪。   解决方案  利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。 即使查询到的数据为空，仍把该空值缓存，还需要设置过期时间。 布隆过滤器，内部维护一系列合法有效的 key 就可以迅速判断出请求所携带的key是否合法有效。如果不合法，则直接返回。    缓存击穿  描述  一个存在的 key，在缓存过期的一刻，恰好在这个时间点对这个 key 有大量的并发请求过来，这个时候大量的请求可能会瞬间瘫痪掉 DB 。   解决方案  分级缓存 互斥锁    缓存预热  描述  系统上线后，提前将数据刷到缓存。避免用户在访问的时候，先去查询数据库。   解决方案  数据量不大的时候，工程启动的时候进行加载缓存 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新 数据量太大的时候，优先保证热点数据进行提前加载到缓存    缓存降级 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据\n","permalink":"https://quicksandznzn.github.io/posts/cache/cache_problem/","summary":"缓存雪崩  描述  大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。   解决方案  分级缓存 给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。    缓存穿透  描述  访问一个不存在的 key 时，缓存不起作用，请求会穿透到 DB ，流量大时 DB 自然就会瘫痪。   解决方案  利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。 即使查询到的数据为空，仍把该空值缓存，还需要设置过期时间。 布隆过滤器，内部维护一系列合法有效的 key 就可以迅速判断出请求所携带的key是否合法有效。如果不合法，则直接返回。    缓存击穿  描述  一个存在的 key，在缓存过期的一刻，恰好在这个时间点对这个 key 有大量的并发请求过来，这个时候大量的请求可能会瞬间瘫痪掉 DB 。   解决方案  分级缓存 互斥锁    缓存预热  描述  系统上线后，提前将数据刷到缓存。避免用户在访问的时候，先去查询数据库。   解决方案  数据量不大的时候，工程启动的时候进行加载缓存 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新 数据量太大的时候，优先保证热点数据进行提前加载到缓存    缓存降级 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据","title":"缓存的场景问题及解决方案"}]